{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0932fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from baseline_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6701b94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 64, 544]           3,136\n",
      "       BatchNorm2d-2          [-1, 64, 64, 544]             128\n",
      "              ReLU-3          [-1, 64, 64, 544]               0\n",
      "         MaxPool2d-4          [-1, 64, 32, 272]               0\n",
      "            Conv2d-5          [-1, 64, 32, 272]          36,864\n",
      "       BatchNorm2d-6          [-1, 64, 32, 272]             128\n",
      "              ReLU-7          [-1, 64, 32, 272]               0\n",
      "            Conv2d-8          [-1, 64, 32, 272]          36,864\n",
      "       BatchNorm2d-9          [-1, 64, 32, 272]             128\n",
      "             ReLU-10          [-1, 64, 32, 272]               0\n",
      "       BasicBlock-11          [-1, 64, 32, 272]               0\n",
      "           Conv2d-12          [-1, 64, 32, 272]          36,864\n",
      "      BatchNorm2d-13          [-1, 64, 32, 272]             128\n",
      "             ReLU-14          [-1, 64, 32, 272]               0\n",
      "           Conv2d-15          [-1, 64, 32, 272]          36,864\n",
      "      BatchNorm2d-16          [-1, 64, 32, 272]             128\n",
      "             ReLU-17          [-1, 64, 32, 272]               0\n",
      "       BasicBlock-18          [-1, 64, 32, 272]               0\n",
      "           Conv2d-19         [-1, 128, 16, 136]          73,728\n",
      "      BatchNorm2d-20         [-1, 128, 16, 136]             256\n",
      "             ReLU-21         [-1, 128, 16, 136]               0\n",
      "           Conv2d-22         [-1, 128, 16, 136]         147,456\n",
      "      BatchNorm2d-23         [-1, 128, 16, 136]             256\n",
      "           Conv2d-24         [-1, 128, 16, 136]           8,192\n",
      "      BatchNorm2d-25         [-1, 128, 16, 136]             256\n",
      "             ReLU-26         [-1, 128, 16, 136]               0\n",
      "       BasicBlock-27         [-1, 128, 16, 136]               0\n",
      "           Conv2d-28         [-1, 128, 16, 136]         147,456\n",
      "      BatchNorm2d-29         [-1, 128, 16, 136]             256\n",
      "             ReLU-30         [-1, 128, 16, 136]               0\n",
      "           Conv2d-31         [-1, 128, 16, 136]         147,456\n",
      "      BatchNorm2d-32         [-1, 128, 16, 136]             256\n",
      "             ReLU-33         [-1, 128, 16, 136]               0\n",
      "       BasicBlock-34         [-1, 128, 16, 136]               0\n",
      "           Conv2d-35           [-1, 256, 8, 68]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 8, 68]             512\n",
      "             ReLU-37           [-1, 256, 8, 68]               0\n",
      "           Conv2d-38           [-1, 256, 8, 68]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 8, 68]             512\n",
      "           Conv2d-40           [-1, 256, 8, 68]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 8, 68]             512\n",
      "             ReLU-42           [-1, 256, 8, 68]               0\n",
      "       BasicBlock-43           [-1, 256, 8, 68]               0\n",
      "           Conv2d-44           [-1, 256, 8, 68]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 8, 68]             512\n",
      "             ReLU-46           [-1, 256, 8, 68]               0\n",
      "           Conv2d-47           [-1, 256, 8, 68]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 8, 68]             512\n",
      "             ReLU-49           [-1, 256, 8, 68]               0\n",
      "       BasicBlock-50           [-1, 256, 8, 68]               0\n",
      "           Conv2d-51           [-1, 128, 8, 68]          32,896\n",
      "ImagePositionalEncoding-52           [-1, 256, 8, 68]               0\n",
      "================================================================\n",
      "Total params: 2,809,408\n",
      "Trainable params: 2,809,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.53\n",
      "Forward/backward pass size (MB): 167.34\n",
      "Params size (MB): 10.72\n",
      "Estimated Total Size (MB): 178.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Encoder(256).to(\"cuda\")\n",
    "\n",
    "summary(model, input_size=(1,128,1088))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e793eace",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (256) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8442/3852241377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePositionalEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m68\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CSE251B/image-to-latex/baseline_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m#print(f'imageencode: x:{x.shape}, self.pe[:, : x.size(2), : x.size(3)] {self.pe[:, : x.size(2), : x.size(3)].shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#print(self.pe.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (256) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "model = ImagePositionalEncoding(256).to(\"cuda\")\n",
    "\n",
    "summary(model, input_size=(1, 256, 8, 68))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
